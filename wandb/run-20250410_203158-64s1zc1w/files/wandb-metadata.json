{
  "os": "Linux-6.11.0-21-generic-x86_64-with-glibc2.39",
  "python": "CPython 3.12.9",
  "startedAt": "2025-04-10T18:31:58.716362Z",
  "args": [
    "--input_bin",
    "data/fineweb10B/fineweb_train_*.bin",
    "--input_val_bin",
    "data/fineweb10B/fineweb_val_*.bin",
    "--output_dir",
    "pylog124M",
    "--model",
    "d12",
    "--batch_size",
    "16",
    "--grad_accumulation_steps",
    "32",
    "--sequence_length",
    "1024",
    "--val_loss_every",
    "128",
    "--val_batch_size",
    "16",
    "--num_iterations",
    "4768",
    "--weight_decay",
    "0.1",
    "--learning_rate",
    "0.0018",
    "--warmup_iters",
    "256",
    "--warmdown_iters",
    "1024",
    "--log_wandb"
  ],
  "program": "/home/modded-nanogpt/train_gpt2.py",
  "codePath": "train_gpt2.py",
  "root": "/home/modded-nanogpt",
  "host": "NoCapMachine",
  "executable": "/home/miniconda3/bin/python",
  "codePathLocal": "train_gpt2.py",
  "cpu_count": 8,
  "cpu_count_logical": 16,
  "gpu": "NVIDIA GeForce RTX 4090",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "1443811328000",
      "used": "727400607744"
    }
  },
  "memory": {
    "total": "66529034240"
  },
  "cpu": {
    "count": 8,
    "countLogical": 16
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA GeForce RTX 4090",
      "memoryTotal": "25757220864",
      "cudaCores": 16384,
      "architecture": "Ada"
    }
  ],
  "cudaVersion": "12.8"
}
